{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0032769400963140283\n",
      "Input with the highest output: 0.9879879879879879\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('data/training_data.csv')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1], df.iloc[:, 2], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost regression model\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Reshape the data to fit the model's requirements\n",
    "X_train = np.array(X_train).reshape(-1, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 1)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Generate a range of inputs\n",
    "inputs = np.linspace(0, 1, num=1000).reshape(-1, 1)\n",
    "\n",
    "# Predict the outputs for the inputs using the trained model\n",
    "outputs = model.predict(inputs)\n",
    "\n",
    "# Find the input with the highest predicted output\n",
    "highest_output_index = np.argmax(outputs)\n",
    "highest_output_input = inputs[highest_output_index][0]\n",
    "\n",
    "print(\"Input with the highest output:\", highest_output_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4/4 [==============================] - 1s 44ms/step - loss: 0.2181 - val_loss: 0.1786\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1510 - val_loss: 0.1228\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1012 - val_loss: 0.0815\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0651 - val_loss: 0.0520\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.0316\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.0179\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "df = pd.read_csv('data/training_data.csv')\n",
    "\n",
    "# Load the input-output pairs from the dataframe\n",
    "inputs = df.iloc[:, 1].values\n",
    "outputs = df.iloc[:, 2].values\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_inputs = inputs[:800]\n",
    "train_outputs = outputs[:800]\n",
    "val_inputs = inputs[800:]\n",
    "val_outputs = outputs[800:]\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=1, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_inputs, train_outputs, epochs=30, batch_size=200, validation_data=(val_inputs, val_outputs))\n",
    "\n",
    "# Use the model to predict the output for a given input\n",
    "input_to_predict = 0.5\n",
    "predicted_output = model.predict(np.array([input_to_predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 463us/step\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Generate a range of input values\n",
    "inputs_to_test = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Use the model to predict the output for each input value\n",
    "predicted_outputs = model.predict(inputs_to_test)\n",
    "\n",
    "# Find the input that corresponds to the highest predicted output\n",
    "index_of_max_output = np.argmax(predicted_outputs)\n",
    "input_with_max_output = inputs_to_test[index_of_max_output]\n",
    "\n",
    "print(input_with_max_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(p2, guess):\n",
    "    def objective(x):\n",
    "            input_to_predict = x\n",
    "            predicted_output = model.predict(np.array([input_to_predict]))\n",
    "            return predicted_output[0][0]\n",
    "\n",
    "    # Define the initial input, the learning rate, and the number of iterations\n",
    "    x = guess\n",
    "    learning_rate = 0.01\n",
    "    num_iterations = 100\n",
    "\n",
    "\n",
    "    iter_vals = []\n",
    "\n",
    "    beta = 0.99\n",
    "    \n",
    "    # Optimize the input using Adam optimization\n",
    "    for i in range(num_iterations):\n",
    "        if len(iter_vals) >= 2 and abs(iter_vals[-1] - iter_vals[-2]) < 0.0005:\n",
    "             break\n",
    "\n",
    "        # Compute the gradient of the objective function using numerical differentiation\n",
    "        gradient = (objective(x + 0.001) - objective(x)) / 0.001\n",
    "       \n",
    "        x += (learning_rate * gradient) * (beta)**i\n",
    "\n",
    "        iter_vals.append(x)\n",
    "\n",
    "        print(x)\n",
    "\n",
    "    return x, objective(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5054380297660828\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5108219742774963\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.5161520793437957\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.5214294617027043\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.5266534976781844\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.5318258601281507\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5369464989536175\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.5420164869450692\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5470346750592119\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5520032257909234\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.5569220910153179\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.5617912339242823\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5666159120165902\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.5713923433279751\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5761215281391017\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.580803421102117\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5854379876271224\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5900257060535816\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.5945680447047393\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.599064467534512\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.6035164136465118\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.6079238402973914\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6122876704908277\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.6166078623823296\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6208843840542515\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6251186041271125\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6293104819992449\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.633459986700989\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6375688960512161\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6416358256093956\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.6456616449762133\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.6496476426361849\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6535942124415108\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6575008887480491\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.661368498291522\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.6651974317395601\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.6689880758531179\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.6727412244692187\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6764564347649167\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.680134895723557\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.6837765720726109\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.6873806474056005\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6909494635919589\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.6944829785117695\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.6979807752560194\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.7014435940328267\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.7048721600260041\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7082664403592497\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.7116260420219713\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.7149524119223255\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.7182455181236762\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "0.7215056932630134\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.7247336200865012\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7279289177405656\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7310919160159126\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.734223970184816\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.737324364303257\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.7403937544805136\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.7434324507559976\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "0.7464410894937501\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.749419641844125\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "0.7523680858015309\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.7552870453193627\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7581768152420162\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.7610376874654431\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7638699509666358\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.7666741988784656\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7694501003359845\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.7721985437143688\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.7749195026589693\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7776129570672984\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "0.7802797689289013\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.7829193345171213\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "0.7855327906360686\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.78812039551857\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.7906818438607504\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.79321795540609\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.7957287058359762\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.7982146209221818\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "0.8006751379795013\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.8031110498662477\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.8055226026341266\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.8079097784379228\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.8102733413057209\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.8126132685448411\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8149300501830512\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "0.8172236640048792\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8194940930650703\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.8217418178346594\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8239670653565526\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8261703016422816\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8283512667384891\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8305104221837346\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8326479860745276\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.834764406059686\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8368594324290523\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "0.8389335085347248\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.8409868438793406\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.843019868472568\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "0.8450325628198632\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "(0.8450325628198632, 0.68663424)\n"
     ]
    }
   ],
   "source": [
    "print(gradient_descent('Default', 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
