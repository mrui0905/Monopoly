{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(p1, p2):\n",
    "    d = {1:0, 2:0}\n",
    "    for _ in range(1000):\n",
    "        winner = init.main(1000, 0, [p1, p2])\n",
    "        d[winner] += 1\n",
    "\n",
    "    win_rate = d[1]/1000\n",
    "    return win_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539\n",
      "0.597\n"
     ]
    }
   ],
   "source": [
    "print(score(0.70, 0.5))\n",
    "print(score(0.80, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(p2, guess):\n",
    "    def objective(x):\n",
    "            return -score(x, p2)\n",
    "\n",
    "    # Define the initial input, the learning rate, and the number of iterations\n",
    "    x = guess\n",
    "    learning_rate = 0.01\n",
    "    num_iterations = 50\n",
    "\n",
    "    # Define the beta parameters for the Adam optimizer\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "\n",
    "    # Define the initial values for the first and second moments\n",
    "    m = 0\n",
    "    v = 0\n",
    "\n",
    "    iter_vals = []\n",
    "\n",
    "    # Optimize the input using Adam optimization\n",
    "    for i in range(num_iterations):\n",
    "        if len(iter_vals) >= 2 and abs(iter_vals[-1] - iter_vals[-2]) < 0.0005:\n",
    "             break\n",
    "\n",
    "        # Compute the gradient of the objective function using numerical differentiation\n",
    "        gradient = (objective(x + 0.001) - objective(x)) / 0.001\n",
    "        # Change the sign of the gradient to maximize the objective function\n",
    "        #gradient = -gradient\n",
    "        # Update the first and second moments\n",
    "        m = beta1 * m + (1 - beta1) * gradient\n",
    "        v = beta2 * v + (1 - beta2) * gradient**2\n",
    "        # Compute the bias-corrected first and second moments\n",
    "        m_hat = m / (1 - beta1**(i+1))\n",
    "        v_hat = v / (1 - beta2**(i+1))\n",
    "        # Update the input using the Adam optimizer\n",
    "        x = x - learning_rate * m_hat / (v_hat**(1/2) + 1e-8)\n",
    "\n",
    "        iter_vals.append(x)\n",
    "\n",
    "        print(x)\n",
    "\n",
    "    return x, score(x, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7900000000032259\n",
      "0.7803978647490034\n",
      "0.7720336223673754\n",
      "0.7693033808419909\n",
      "0.7661561155997165\n",
      "0.7610619569174661\n",
      "0.7543665013021877\n",
      "0.750890637216982\n",
      "0.7488750373711317\n",
      "0.7478987895810434\n",
      "0.7445145350214086\n",
      "0.7417830564643616\n",
      "0.7387802185298251\n",
      "0.7365347932796241\n",
      "0.7337734647097174\n",
      "0.7315788680059311\n",
      "0.7285448874853775\n",
      "0.7266686619259888\n",
      "0.724814687434162\n",
      "0.7242500717627264\n",
      "0.72180240755199\n",
      "0.718161707984016\n",
      "0.715780048867016\n",
      "0.7133891351066971\n",
      "0.7094800446657824\n",
      "0.7083397147369838\n",
      "0.7071016566104281\n",
      "0.7071459040492122\n",
      "(0.7071459040492122, 0.55)\n"
     ]
    }
   ],
   "source": [
    "print(gradient_descent('Default', 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(p2, guess):\n",
    "    def objective(x):\n",
    "            return score(x, p2)\n",
    "\n",
    "    # Define the initial input, the learning rate, and the number of iterations\n",
    "    x = guess\n",
    "    learning_rate = 0.01\n",
    "    num_iterations = 50\n",
    "\n",
    "\n",
    "    iter_vals = []\n",
    "\n",
    "    # Optimize the input using Adam optimization\n",
    "    for i in range(num_iterations):\n",
    "        if len(iter_vals) >= 2 and abs(iter_vals[-1] - iter_vals[-2]) < 0.0005:\n",
    "             break\n",
    "\n",
    "        # Compute the gradient of the objective function using numerical differentiation\n",
    "        gradient = (objective(x + 0.001) - objective(x)) / 0.001\n",
    "       \n",
    "        x += learning_rate * gradient\n",
    "\n",
    "        iter_vals.append(x)\n",
    "\n",
    "        print(x)\n",
    "\n",
    "    return x, score(x, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2800000000000005\n",
      "1.0600000000000014\n",
      "1.3200000000000005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(gradient_descent(\u001b[39m'\u001b[39;49m\u001b[39mDefault\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0.8\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[104], line 19\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(p2, guess)\u001b[0m\n\u001b[1;32m     16\u001b[0m      \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Compute the gradient of the objective function using numerical differentiation\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m gradient \u001b[39m=\u001b[39m (objective(x \u001b[39m+\u001b[39m \u001b[39m0.001\u001b[39m) \u001b[39m-\u001b[39m objective(x)) \u001b[39m/\u001b[39m \u001b[39m0.001\u001b[39m\n\u001b[1;32m     21\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m gradient\n\u001b[1;32m     23\u001b[0m iter_vals\u001b[39m.\u001b[39mappend(x)\n",
      "Cell \u001b[0;32mIn[104], line 3\u001b[0m, in \u001b[0;36mgradient_descent.<locals>.objective\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(x):\n\u001b[0;32m----> 3\u001b[0m         \u001b[39mreturn\u001b[39;00m score(x, p2)\n",
      "Cell \u001b[0;32mIn[95], line 4\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(p1, p2)\u001b[0m\n\u001b[1;32m      2\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m:\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m:\u001b[39m0\u001b[39m}\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     winner \u001b[39m=\u001b[39m init\u001b[39m.\u001b[39;49mmain(\u001b[39m1000\u001b[39;49m, \u001b[39m0\u001b[39;49m, [p1, p2])\n\u001b[1;32m      5\u001b[0m     d[winner] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      7\u001b[0m win_rate \u001b[39m=\u001b[39m d[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m\n",
      "File \u001b[0;32m~/Documents/College/Summer 23/Monopoly/init.py:690\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(limit_turns, game_mode, player_modes)\u001b[0m\n\u001b[1;32m    688\u001b[0m rolls \u001b[39m=\u001b[39m []\n\u001b[1;32m    689\u001b[0m \u001b[39mwhile\u001b[39;00m double \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(rolls) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 690\u001b[0m     roll, double \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39;49mdice_roll(\u001b[39mlen\u001b[39;49m(rolls))\n\u001b[1;32m    691\u001b[0m     rolls\u001b[39m.\u001b[39mappend(roll)\n\u001b[1;32m    693\u001b[0m \u001b[39m#print(rolls)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/College/Summer 23/Monopoly/init.py:214\u001b[0m, in \u001b[0;36mGame.dice_roll\u001b[0;34m(self, reroll_count)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdice_roll\u001b[39m(\u001b[39mself\u001b[39m, reroll_count):\n\u001b[1;32m    213\u001b[0m     a \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m1\u001b[39m, \u001b[39m6\u001b[39m)\n\u001b[0;32m--> 214\u001b[0m     b \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mrandint(\u001b[39m1\u001b[39;49m, \u001b[39m6\u001b[39;49m)\n\u001b[1;32m    215\u001b[0m     \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m a \u001b[39m+\u001b[39m b\n\u001b[1;32m    216\u001b[0m     double \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/random.py:358\u001b[0m, in \u001b[0;36mRandom.randint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mempty range for randrange()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m     \u001b[39mreturn\u001b[39;00m istart \u001b[39m+\u001b[39m istep \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_randbelow(n)\n\u001b[0;32m--> 358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandint\u001b[39m(\u001b[39mself\u001b[39m, a, b):\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandrange(a, b\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gradient_descent('Default', 0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
